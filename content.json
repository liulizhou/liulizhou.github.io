{"pages":[{"title":"关于我","text":"","link":"/about/index.html"},{"title":"文章类别","text":"","link":"/categories/index.html"},{"title":"文章标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"2019_qingmin_guiyang","text":"2019年清明节，我去了贵阳旅游。","link":"/2019/04/03/2019-qingmin-guiyang/"},{"title":"Artifact Reduction Project","text":"本文档简单介绍AR项目及C++ API。 ENCD Project介绍ENCD项目主要是用于去除图像或视频由于压缩导致的块效应和振铃效应，项目有python实现部分和C++实现部分，Python主要用于训练生成模型，C++主要是实现Python生成模型的前匮网络和一些数据处理，用于部署。项目地址：ftp /liulizhou/ENCDopencv源码地址：ftp /liulizhou/opencvlibtorch库地址：ftp /liulizhou/libtorch目录结构： .├── CMakeLists.txt├── dataprocess.cpp├── dataprocess.h├── encd.cpp├── encd.h├── img│ ├── blockresult.png│ ├── m_01702.png│ ├── plant_1000.yuv_90.yuv│ ├── plant_500.yuv_375.yuv│ ├── plant_500.yuv_405.yuv│ ├── plant_500.yuv_45.yuv│ ├── plant_500.yuv_540.yuv│ ├── plant_500.yuv_570.yuv│ ├── plant_500.yuv_690.yuv│ ├── plant_500.yuv_90.yuv│ ├── ringingtest.jpg│ └── ringingtestresult.png├── latest_scriptnet_G.pth├── model.pt├── model.pth├── netG_trace_final.pth├── pycvt.cpp├── README.md├── real_a_s.bin├── resnet18.pth├── test_train.pth├── test_utils.cpp├── test_utils.h├── utils.cpp├── utils.h├── v_tensor.bin├── yuv.cpp└── yuv.h 目录中使用测试模型：latest_scriptnet_G.pth目录中yuv文件图像大小：width 1920 height 1080 块效应 振铃效应 伴随着轻微的模糊效应，原因在于模型使用旧的模型，样本中没有加入高斯模糊对抗样本 工程依赖 libtorch opencv libtorchlibtorch，用于实现python训练生成模型的前匮网络计算，支持CPU和GPU，libtorch库下载，提供动态和静态链接库和头文件，可直接链接到工程中。 opencv opencv source下载如上 install mkdir build &amp;&amp; cd buildcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D WITH_V4L=ON -D INSTALL_C_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D WITH_GTK2=ON -D WITH_OPENGL=ON ..make -j7make install 编译ENCD工程工程使用C++11标准，主要依赖opencv和libtorch库，opencv在cmakelist文件中通过find_package自动寻找库安装路径，需要指定libtorch库路径进行编译，命令如下： cmake -DCMAKE-PREFIX-PATH=/path-to-libtorch .. 命令行使用编译完成后，生成pycvt可执行文件，可运行程序进行图像或视频质量增强。 处理yuv文件： ./pycvt --model path-to-model --yuvfi path-to-yuv-file --width w --height h 处理图像文件： ./pycvt --model path-to-model --image path-to-image-file 处理bin文件： ./pycvt --model path-to-model --bin path-to-bin-file --width w --height h 处理视频文件： ./pycvt --model path-to-model --video path-to-vide-file 静态库文件使用编译完成后，会生成动态shencd.so和静态库文件stencd.a，可集成到项目中,主要使用其中对yuv数据进行增强函数，函数定义如下： @param src: source yuv420 data@param dst: enhanced output yuv420 data@param width: src yuv420 data width@param height: src yuv420 data height@param model_path: model path for image enhancdvoid encd_image_fix(uint8_t* src, uint8_t* dst, int width, int height, string model_path) 性能测试测试图像例子： width: 1024height: 576model size: 6.2Mmodel init: 19.71msdata preprocess: 84.16msforward: 16.21ms","link":"/2018/12/11/Artifact-Reduction-Project/"},{"title":"deep-learning-architecture","text":"fastai量子位 automlfasttext","link":"/2019/01/07/deep-learning-architecture/"},{"title":"deep-learning-report","text":"这篇文章主要记录深度学习report的内容 提纲 研究热点 方法论（反向传播算法） GAN 超分辨 图像增强，HDR","link":"/2019/01/21/deep-learning-report/"},{"title":"i3wm-using-skills","text":"这篇文章记录的是linux下i3窗口管理器的使用方法和技巧","link":"/2018/09/30/i3wm-using-skills/"},{"title":"libtorch和gflags的编译安装问题","text":"这篇文章记录了gflags的安装、libtorch的安装以及过程中的一些问题 gflags说明libtorch说明gflags安装libtorch安装[bug] gflags和libtorch冲突问题我们可能在CMakeList.txt文件中像这样链接gflags和libtorch的库(error): target_link_libraries(pycvt \"$&#123;TORCH_LIBRARIES&#125;\" gflags)备注：其中的pycvt是程序名。 文件CMakeList.txt中的链接命令是没有问题的，但是我们make编译链接库的过程中，可能会出现下面的问题： CMakeFiles/pycvt.dir/pycvt.cpp.o：在函数‘main’中：pycvt.cpp:(.text+0xe1)：对‘google::ParseCommandLineFlags(int*, char***, bool)’未定义的引用CMakeFiles/pycvt.dir/pycvt.cpp.o：在函数‘__static_initialization_and_destruction_0(int, int)’中：pycvt.cpp:(.text+0x4c5)：对‘google::FlagRegisterer::FlagRegisterer&lt;std::string&gt;(char const*, char const*, char const*, std::string*, std::string*)’未定义的引用pycvt.cpp:(.text+0x568)：对‘google::FlagRegisterer::FlagRegisterer&lt;std::string&gt;(char const*, char const*, char const*, std::string*, std::string*)’未定义的引用pycvt.cpp:(.text+0x60b)：对‘google::FlagRegisterer::FlagRegisterer&lt;std::string&gt;(char const*, char const*, char const*, std::string*, std::string*)’未定义的引用pycvt.cpp:(.text+0x6ae)：对‘google::FlagRegisterer::FlagRegisterer&lt;std::string&gt;(char const*, char const*, char const*, std::string*, std::string*)’未定义的引用pycvt.cpp:(.text+0x709)：对‘google::FlagRegisterer::FlagRegisterer&lt;int&gt;(char const*, char const*, char const*, int*, int*)’未定义的引用pycvt.cpp:(.text+0x72e)：对‘google::FlagRegisterer::FlagRegisterer&lt;int&gt;(char const*, char const*, char const*, int*, int*)’未定义的引用pycvt.cpp:(.text+0x79b)：对‘google::FlagRegisterer::FlagRegisterer&lt;std::string&gt;(char const*, char const*, char const*, std::string*, std::string*)’未定义的引用pycvt.cpp:(.text+0x83e)：对‘google::FlagRegisterer::FlagRegisterer&lt;std::string&gt;(char const*, char const*, char const*, std::string*, std::string*)’未定义的引用 出现这个问题的原因是libtorch中自带了gflags（在c10命名空间下），所以如果我们想使用gflags, 用libtorch自带的就可以了，比如gflags中是这样添加命令的： DEFINE_string(model, \"valid\", \"the torch model path\"); gflags::ParseCommandLineFlags(&amp;argc, &amp;argv, true); 我们换成libtorch库下的gflags，应该是这样的： C10_DEFINE_string(model, \"valid\", \"the torch model path\"); c10::ParseCommandLineFlags(&amp;argc, &amp;argv);","link":"/2018/11/15/gflags-and-libtorch-compile-problem/"},{"title":"Compression Artifacts Removal Using Convolutional Neural Networks","text":"论文分析，文章2015年发表在ICCV上，使用深度学习做压缩失真消除 这是ICCV2015年的一篇文章，算是比较早用深度学习做压缩失真消除，后面的大多数方法都是与这篇文章里面的去除效果做对比。","link":"/2018/09/20/iccv-2015-arcnn/"},{"title":"conda-using-skill","text":"本文记录了conda的一些使用方法和技巧参考 安装虚拟环境管理查看所有虚拟环境： conda info --envs 查看当前虚拟环境： conda info -e 创建新的虚拟环境： # version即是创建虚拟环境的python版本，必须指定conda create -n env_name python=version# 创建虚拟环境的同时安装包conda create -n env_name pytorch-nightly python=version 环境切换： # 切换source activate env_name# 推出环境codna deactivate 移除环境 conda remove -n env_name --all 包管理conda install python=3.6conda create -n pytorch_py3.6 python=3.6 source activate pytorch_py3.6conda install pytorch-cpu torchvision-cpu -c pytorch","link":"/2018/11/30/conda-using-skill/"},{"title":"Libtorch中的bug","text":"这篇文件记录了使用libtorch过程中运到的一些bug module-&gt;get_parameters()使用下面的调用方式： const torch::OrderedDict&lt;std::string, torch::jit::script::NamedParameter&gt; param = module-&gt;get_parameters(); 报下面的错误： /usr/include/c++/5/ext/new_allocator.h:120:4: error: use of deleted function ‘torch::OrderedDict&lt;std::basic_string&lt;char&gt;, torch::jit::script::NamedParameter&gt;::Item::Item(const torch::OrderedDict&lt;std::basic_string&lt;char&gt;, torch::jit::script::NamedParameter&gt;::Item&amp;)’&#123; ::new((void *)__p) _Up(std::forward&lt;_Args&gt;(__args)...); &#125; 需要看下get_parameters()的返回类型： const torch::OrderedDict&lt;std::string, NamedParameter&gt;&amp; get_parameters() const &#123; return parameters;&#125; get_parameters()返回的是const类型的引用，不能使用一个引用赋值给一个对象，应该使用下面的调用方式： const torch::OrderedDict&lt;std::string, torch::jit::script::NamedParameter&gt;&amp; param = module-&gt;get_parameters(); 这里论述下面的两个问题： 关于const的使用关于引用、对象的使用libtorch和pytorch的版本问题高版本的pytorch trace生成的model不能用低版本的litorch load, 否则报下面的异常： terminate called after throwing an instance of 'c10::Error' what(): tag == RecordTags::FOOTER ASSERT FAILED at /pytorch/caffe2/serialize/inline_container.h:234, please report a bug to PyTorch. File footer has wrong record type. Is this file corrupted? (readAndValidateFileFooter at /pytorch/caffe2/serialize/inline_container.h:234)frame #0: std::function&lt;std::string ()&gt;::operator()() const + 0x11 (0x7f95aad91b81 in /data/source/libtorch/lib/libc10.so)frame #1: c10::Error::Error(c10::SourceLocation, std::string const&amp;) + 0x2a (0x7f95aad9144a in /data/source/libtorch/lib/libc10.so)frame #2: &lt;unknown function&gt; + 0x682b0e (0x7f95d7c91b0e in /data/source/libtorch/lib/libtorch.so.1)frame #3: &lt;unknown function&gt; + 0x686833 (0x7f95d7c95833 in /data/source/libtorch/lib/libtorch.so.1)frame #4: &lt;unknown function&gt; + 0x67b5f9 (0x7f95d7c8a5f9 in /data/source/libtorch/lib/libtorch.so.1)frame #5: torch::jit::load(std::istream&amp;) + 0x7c (0x7f95d7c9018c in /data/source/libtorch/lib/libtorch.so.1)frame #6: torch::jit::load(std::string const&amp;) + 0x130 (0x7f95d7c903b0 in /data/source/libtorch/lib/libtorch.so.1)frame #7: init_model(std::shared_ptr&lt;torch::jit::script::Module&gt;&amp;, std::string) + 0x50 (0x43d9d0 in ./pycvt)frame #8: main + 0x8f (0x452862 in ./pycvt)frame #9: __libc_start_main + 0xf0 (0x7f95aa433830 in /lib/x86_64-linux-gnu/libc.so.6)frame #10: _start + 0x29 (0x43c4b9 in ./pycvt)已放弃 qiyi-ffmpeg链接libtorch主要功能文件如下： vf_qrestore.c filter功能实现文件，ffmpeg调用转换得到数据类型后调用qrestore_wrapper qrestore_wrapper.cpp 使用c规则包裹C++函数供ffmpeg编译，编译生成qrestore_wrapper.a qrestore.cpp 使用c++实现质量恢复供包裹函数wrapper调用，编译生成qrestore.a 测试简单版本vf_qrestore.c和wrapper没有问题 qiiyi-ffmpeg编译 ./configure --enable-cross-compile --enable-yasm --enable-static --enable-nonfree --enable-gpl --disable-filter=intertrustwm --disable-filter=iqiyiwm --disable-filter=css --disable-optimizations --extra-cflags=\"-I/home/maxliu/eclipse_201908-workspace/wrappertest/src -I/home/maxliu/eclipse_201908-workspace/Qrestore/src\" --extra-ldflags=\"-L/data/source/libtorch/lib -L/home/maxliu/eclipse_201908-workspace/wrappertest/src -L/home/maxliu/eclipse_201908-workspace/Qrestore/src/build\" --extra-libs='-lCppAddWrapper -lCppAdd -lstqrestore_wrapper -lstqrestore -ltorch -lc10_cuda -lc10 -llibcudart-5d6d23a3.so.8.0.61 -llibgomp-7bcb08ae.so.1 -llibnvrtc-56d4825a.so.8.0.61 -lnvrtc-builtins -llibnvToolsExt-422e3301.so.1 -llibtorch.so.1 -lstdc++' --prefix=/usr/local/ffmpeg_new_master --extra-libs=&#39;-lCppAddWrapper -lCppAdd中-lCppAddWrapper和-lCppAdd顺序不能颠倒 configure_qiyi_simple.sh通过，编译Error: gcc is unable to create an executable file.If gcc is a cross-compiler, use the --enable-cross-compile option.Only do this if you know what cross compiling means.C compiler test failed. 编译pytorch source [ 68%] Linking CXX shared library ../lib/libcaffe2.so[ 68%] Built target caffe2Makefile:140: recipe for target 'all' failedmake: *** [all] Error 2Failed to run 'bash ../tools/build_pytorch_libs.sh --use-cuda --use-fbgemm --use-nnpack --use-mkldnn --use-qnnpack caffe2' 编译pytorch source需要cuDNN &gt; 7, ATen 模块至少需要6以上版本，所以最好更新cudnn到比较高的版本","link":"/2018/12/03/libtorch-bug-index/"},{"title":"linux-any-commands","text":"本篇文章记录了linux各种各样的非常常用而且重要的命令用法 文件查找我们比较常用的两种查找方式，一种是查找文件中的字符，一种是查找文件 grep查找文件中的字符对文件中的字符进行查找使用grep，grep命令参数如下： maxliu@maxliu-tp:~/eclipse_201908-workspace/pycvt/src/build$ grep --help用法: grep [选项]... PATTERN [FILE]...在每个 FILE 或是标准输入中查找 PATTERN。默认的 PATTERN 是一个基本正则表达式(缩写为 BRE)。例如: grep -i 'hello world' menu.h main.c正则表达式选择与解释: -E, --extended-regexp PATTERN 是一个可扩展的正则表达式(缩写为 ERE) -F, --fixed-strings PATTERN 是一组由断行符分隔的字符串。 -G, --basic-regexp PATTERN 是一个基本正则表达式(缩写为 BRE) -P, --perl-regexp PATTERN 是一个 Perl 正则表达式 -e, --regexp=PATTERN 用 PATTERN 来进行匹配操作 -f, --file=FILE 从 FILE 中取得 PATTERN -i, --ignore-case 忽略大小写 -w, --word-regexp 强制 PATTERN 仅完全匹配字词 -x, --line-regexp 强制 PATTERN 仅完全匹配一行 -z, --null-data 一个 0 字节的数据行，但不是空行杂项: -s, --no-messages 不显示错误信息 -v, --invert-match 选中不匹配的行 -V, --version 显示版本信息并退出 --help 显示此帮助并退出输出控制: -m, --max-count=NUM NUM 次匹配后停止 -b, --byte-offset 输出的同时打印字节偏移 -n, --line-number 输出的同时打印行号 --line-buffered 每行输出清空 -H, --with-filename 为每一匹配项打印文件名 -h, --no-filename 输出时不显示文件名前缀 --label=LABEL 将LABEL 作为标准输入文件名前缀 -o, --only-matching 只显示匹配PATTERN 部分的行 -q, --quiet, --silent 不显示所有常规输出 --binary-files=TYPE 设定二进制文件的TYPE 类型； TYPE 可以是`binary', `text', 或`without-match' -a, --text 等同于 --binary-files=text -I 等同于 --binary-files=without-match -d, --directories=ACTION 读取目录的方式； ACTION 可以是`read', `recurse',或`skip' -D, --devices=ACTION 读取设备、先入先出队列、套接字的方式； ACTION 可以是`read'或`skip' -r, --recursive 等同于--directories=recurse -R, --dereference-recursive 同上，但遍历所有符号链接 --include=FILE_PATTERN 只查找匹配FILE_PATTERN 的文件 --exclude=FILE_PATTERN 跳过匹配FILE_PATTERN 的文件和目录 --exclude-from=FILE 跳过所有除FILE 以外的文件 --exclude-dir=PATTERN 跳过所有匹配PATTERN 的目录。 -L, --files-without-match 只打印不匹配FILEs 的文件名 -l, --files-with-matches 只打印匹配FILES 的文件名 -c, --count 只打印每个FILE 中的匹配行数目 -T, --initial-tab 行首tabs 分隔（如有必要） -Z, --null 在FILE 文件最后打印空字符文件控制: -B, --before-context=NUM 打印文本及其前面NUM 行 -A, --after-context=NUM 打印文本及其后面NUM 行 -C, --context=NUM 打印NUM 行输出文本 -NUM 等同于 --context=NUM --color[=WHEN], --colour[=WHEN] 使用标记高亮匹配字串； WHEN 可以是`always', `never'或`auto' -U, --binary 不要清除行尾的CR 字符(MSDOS/Windows) -u, --unix-byte-offsets 忽略CR 字符，报告字节偏移 (MSDOS/Windows) 对单个文件查找，如果文件较少，我们可以利用cat将文件内容输出到标准控制台，然后使用grep进行字符匹配： cat filepath | grep 'string' 或者按照grep前面所示的基本用法grep [选项]... PATTERN [FILE]来查找文件： grep -s string filepath 对目录下的所有文件进行查找（不查找子目录）： grep -s string dir 递归对目录下的所有文件进行查找： grep -s -R string dir find查找文件简单命令 重新安装软件包 sudo apt-get install --reinstall 软件包 命令命令帮助文档链接 man commandcommand –help常用命令# 查看动态库依赖 ldd # 查看命令执行路径 which # 显示关于ELF 格式文件内容信息 readelf # 解析符号 c++filt # 查询库文件中的字符串 nm # 输出所有环境变量 export -p # 输出某个环境变量值 echo $LD_LIBRARY_PATH # 导入环境变量 export LD_LIBRARY_PATH=/path-to-lib:$LD_LIBRARY_PATH # 递归查看所有目录文件中的字符 grep -s -R string dir # 文件及目录个数统计，参考博客 查看当前目录下的文件数量（不包含子目录中的文件） ls -l | grep &quot;^-&quot; | wc -l 查看当前目录下的文件数量（包含子目录中的文件）注意：R代表子目录 ls -lR | grep &quot;^-&quot; | wc -l 查看当前目录下的文件夹目录个数（不包含子目录中的目录），同上述理，如果需要查看子目录的，加上R ls -l|grep &quot;^d&quot;| wc -l 查询当前路径下的指定前缀名的目录下的所有文件数量，例如：统计所有以“20161124”开头的目录下的全部文件数量ls -lR 20161124*/|grep &quot;^-&quot;| wc -l","link":"/2018/11/16/linux-any-commands/"},{"title":"Linux中的磁盘挂载","text":"这篇博客主要探讨了磁盘（包括U盘）分区和挂载的一些问题。 探讨的问题说明 Linux中的文件系统 如何对新硬盘进行分区并挂载 如何对U盘进行挂载 linux中的文件系统首先我们认识下linux中的文件系统 如何对新硬盘进行分区并挂载写作参考网址：http://www.cnblogs.com/fieldtianye/p/9295986.html 如何对U盘进行挂载bug index对硬盘使用命令分区 sudo fdisk /dev/sdb 挂载出现下面的错误 mount: wrong fs type, bad option, bad superblock on /dev/sdb1, missing codepage or helper program, or other error In some cases useful info is found in syslog - try dmesg | tail or so. 解决方案参考,错误在于对磁盘进行分区后没有创建文件系统类型，可使用下面命令 sudo mkfs.ext4 /dev/sdb1","link":"/2018/11/07/linux-mount-command/"},{"title":"linux-install-index","text":"这篇文章记录了linux下一些软件的安装方法。 protobuf该地址下载最新版本, 这里我我下载的是protobuf-all-3.6.1.tar.gz,解压： tar -xf protobuf-3.6.1 &amp;&amp; cd protobuf-3.6.1./configuremakemake checksudo make install","link":"/2018/11/19/linux-install-index/"},{"title":"liulizhou","text":"Hello Kitty","link":"/2018/09/20/liulizhou/"},{"title":"Pytorch API中的卷积与反卷积操作","text":"本篇文章解析卷积与反卷积操作以及Pytorch中的相关API","link":"/2018/09/27/pytorch-api-Conv-Deconv/"},{"title":"pytorch-bug-index","text":"本文记录了pytorch中碰到的一些bug [error]RuntimeError: Couldn’t export Python operator &lt;python_value&gt;Pytorch训练过程中使用torch.jit.ScriptModule来trace模型，net.save(path)保存模型时候出现下面的错误： Traceback (most recent call last):File \"train.py\", line 69, in &lt;module&gt; train(opt, data_loader, model, visualizer) File \"train.py\", line 42, in train model.save('latest') File \"/opt/ml/job/models/conditional_gan_model.py\", line 132, in save self.save_network(self.netG, 'G', label, self.gpu_ids) File \"/opt/ml/job/models/base_model.py\", line 49, in save_network network.save(save_path)RuntimeError: Couldn't export Python operator &lt;python_value&gt;Defined at:@torch.jit.script_methoddef forward(self, x): output = self.model(x) ~~~~~~~~~~ &lt;--- HERE return output===============End of job stdout&amp;stderr============== [error] Import Error安装完pytorch后，导入import torch,出现下面的错误： Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"/home/maxliu/anaconda3/lib/python3.7/site-packages/torch/__init__.py\", line 84, in &lt;module&gt; from torch._C import *ImportError: /home/maxliu/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_python.so: undefined symbol: _ZNK3c104Type11isSubtypeOfESt10shared_ptrIS0_E 首先我能够明确安装nvidia, cuda, cudnn没有任何问题，那么问题出在哪里了呢，使用命令查看这个符号： c++filt _ZNK3c104Type11isSubtypeOfESt10shared_ptrIS0_E 得到下面的函数： c10::Type::isSubtypeOf(std::shared_ptr&lt;c10::Type&gt;) const 这里怀疑在搜索c10的库时候链接的版本库出了问题，因为安装的pytorch是最新的版本，而我之前使用过旧的libtorch版本，并且加入到了LD_LIBRARY_PATH，echo $LD_LIBRARY_PATH查看LD_LIBRARY_PATH： /usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/data/source/libtorch/lib: 其中/data/source/libtorch/lib就是我之前加入的旧库，import torch引入了旧的库导致找不到符号，在LD_LIBRARY_PATH中去除这个库即可。","link":"/2018/11/30/pytorch-debug-index/"},{"title":"tmux-using-skills","text":"这篇文章记录了tmux的一些使用技巧。 启用鼠标滚屏和窗口切换我们安装tmux后，默认是没有启用鼠标滚屏的，必须按下Ctrl+b后使用PageUp和PageDown来翻页，这样浏览不如自由滚动窗口方便，我们可以开启鼠标滚屏和窗口切换，编辑tmux的配置文件，配置文件在~/.tmux.conf，如果没有需要自己创建一个，文件中加入下面的指令，这个指令重写了Mouse-mode的一系列指令，包括窗格切换、调整窗格大小、窗口切换(窗口：window，窗格pane),指令： set -g mouse on 使文件生效(不要使用source ~/.tmux.conf,无法识别tmux的指令，例如setw，not found)： tmux source-file ~/.tmux.conf 另外启用鼠标后，不能正常的复制tmux中的内容和粘贴，复制tmux中的内容时需要按住Shift键，可以使用Shift+Insert粘贴剪贴板内容到命令行。","link":"/2018/09/30/tmux-using-skills/"},{"title":"各种安装BUG记录","text":"本博客是一个系列博客，记录了我碰到的各种软件安装问题。 Anaconda安装opencv3最常见的使用Anaconda安装opencv3的命令： conda install -c menpo opencv3 如果使用上述命令，可能会出现包冲突问题，我使用conda5.3.0=py37,出现了以下包冲突问题： UnsatisfiableError: The following specifications were found to be in conflict:- anaconda5.3.0=py37_0 -&gt; hdf51.10.2=hba1933b_1- anaconda5.3.0=py37_0 -&gt; mkl-service1.1.2=py37h90e4bf4_5- anaconda5.3.0=py37_0 -&gt; numexpr2.6.8=py37hd89afb7_0- anaconda5.3.0=py37_0 -&gt; pango1.42.4=h049681c_0 -&gt; harfbuzz[version='&gt;=1.7.6,&lt;2.0a0']&gt; - anaconda5.3.0=py37_0 -&gt; scikit-learn0.19.2=py37h4989274_0- opencv3 解决这个问题参考了这个网址，使用下面的命令： conda install -c conda-forge opencv 使用conda上述命令直接安装Opencv，可以正常使用，但是imshow依赖第三分GUI，无法正常显示图像，imshow出现下面的问题： cv2.error: OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/highgui/src/window.cpp:632: error: (-2:Unspecified error) The function is not implemented. 解决办法就是自己编译Opencv,打开开关GTK+2.x,这里给出我的cmake配置(下面一个bug index也讨论到了无法显示GUI的问题，下面的bug index给出的cmake没有配置python-opencv，这个给出编译python的cmake配置)： cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D WITH_GTK2=ON -D WITH_OPENGL=ON -D PYTHON3_EXECUTABLE=~/anaconda3/bin/python3.7 -D PYTHON_INCLUDE_DIR=~/anaconda3/include/python3.7m -D PYTHON_LIBRARY=~/anaconda3/lib/python3.7/site-packages/numpy/core/include/ .. cmake主要是打开GUI配置项WITH_GTK2=ON，配置python路径。 make -j7make install 成功编译安装Opencv后，在python中还不能import cv2,还需要设置一下，取Opencv的安装路径下找到下面的文件（我的安装路径/usr/local）： /usr/local/lib/python3.7/site-packages/cv2.cpython-37m-x86_64-linux-gnu.so 复制到anaconda的site-packages,这个site-packages就是我们cmake配置里的那个。如果你不知道这个这个路径，可以在python代码中打印出来： &gt;&gt;&gt; import sys&gt;&gt;&gt; print(next(p for p in sys.path if 'site-packages' in p))/home/maxliu/anaconda3/lib/python3.7/site-packages 接下来拷贝cv2文件： cp /usr/local/lib/python3.7/site-packages/cv2.cpython-37m-x86_64-linux-gnu.so /home/maxliu/anaconda3/lib/python3.7/site-packages python中成功import cv2。参考 eclipse c++中不能添加带版本号的库这里以libtorch为例来说明这个情况。 我们下载libtorch后，解压得到libtorch库如下： libbenchmark.a libcaffe2_protos.a libcudart-5d6d23a3.so.8.0.61 libnnpack.a libnvToolsExt-422e3301.so.1 libonnx_proto.a libshm.solibbenchmark_main.a libcaffe2.so libgomp-7bcb08ae.so libnnpack_reference_layers.a libonnx.a libprotobuf.a libtorch.solibc10.so libclog.a libgomp-7bcb08ae.so.1 libnvrtc-56d4825a.so libonnxifi_dummy.so libprotobuf-lite.a libtorch.so.1libcaffe2_gpu.so libcpuinfo.a libgtest.a libnvrtc-56d4825a.so.8.0.61 libonnxifi_loader.a libprotoc.alibcaffe2_module_test_dynamic.so libcudart-5d6d23a3.so libgtest_main.a libnvrtc-builtins.so libonnxifi.so libpthreadpool.a 上面的库中，我们主要使用libtorch.so, 我们ldd看下libtorch.so的依赖项： ldd libtorch.so 得到下面的依赖项： maxliu@maxliu-tp:/data/source/libtorch/lib$ ldd libtorch.so linux-vdso.so.1 =&gt; (0x00007ffc1d396000) libnvToolsExt-422e3301.so.1 =&gt; /data/source/libtorch/lib/libnvToolsExt-422e3301.so.1 (0x00007f83c70de000) libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f83c6eda000) librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007f83c6cd2000) libcaffe2.so =&gt; /data/source/libtorch/lib/libcaffe2.so (0x00007f83be54d000) libcaffe2_gpu.so =&gt; /data/source/libtorch/lib/libcaffe2_gpu.so (0x00007f839ce71000) libc10.so =&gt; /data/source/libtorch/lib/libc10.so (0x00007f839cc59000) libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f839ca3c000) libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f839c733000) libstdc++.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f839c3b1000) libgcc_s.so.1 =&gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f839c19b000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f839bdd1000) /lib64/ld-linux-x86-64.so.2 (0x00007f83c809b000) libgomp-7bcb08ae.so.1 =&gt; /data/source/libtorch/lib/libgomp-7bcb08ae.so.1 (0x00007f839bba7000) 我们可以看到libtorch.so依赖libnvToolsExt-422e3301.so.1，这个so文件带版本号，而我们在eclipse中添加库时，只能添加so文件的名字，也就是nvToolsExt-422e3301, eclipse调用g++使用参数-l进行链接，即-lnvToolsExt-422e3301，在实际链接库会自动补上前缀lib和后缀so，所以无法找到带版本号的库，碰到这个问题，我目前还没有找到解决方法，不行的话我们还是写CMakeList来解决吧。 cmake编译安装Opencv3.4后，无法显示GUIg++编译运行出现imshow无法显示的问题： terminate called after throwing an instance of 'cv::Exception'what(): OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/highgui/src/window.cpp:632: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Carbon support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage' 按照error安装GTK和QT（linux下的gui支持），我下载Opncv3.4的版本安装QT4.x(注意这里不能安装QT5.x, 因为opencv3.4不支持配置QT5.x): sudo apt-get updatesudo apt-get install qt4*osudo apt-get install qtcreator 安装GTK+2.x: sudo apt-get install libgtk2.0-dev 配置Opencv, Cmkae命令如下： cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D WITH_GTK2=ON -D WITH_OPENGL=ON ..O 我试验了下，好像不能同时开启QT和GTK, 我这里开启了GTK+2.x(我也安装了GTK+3.x,我没有试验能不能顺利编译通过，有兴趣的可以试验下，使用WITH_GTK=ON默认会使用GTK+3.x)查看配置结果，GTK+2.x配置成功： -- GUI:-- GTK+: YES (ver 2.24.30)-- GThread : YES (ver 2.48.2)-- GtkGlExt: NO-- OpenGL support: NO-- VTK support: NO 我使用GTK+2.x成功了，如果你使用GTK+2.x失败，可以参考Stackoverflow, 配置使用GTK+3.x代替，安装GTK+3.x: sudo apt-get install libgtk-3-dev 重新执行上面的cmake配置命令，make &amp;&amp; make install. 编译Opencv bug真的是莫名其妙的bug，整了一天，最后重装了protobuf就好了，真的很莫名其妙！！！ 安装PIL使用conda安装： conda install pil 出现下面的bug： UnsatisfiableError: The following specifications were found to be in conflict: - pil -&gt; python 2.6* - python 3.6* 可能是由于pil包不支持跑一趟python3,安装pillow，同时支持python2和python3: conda install pillow","link":"/2018/11/07/install-problems-index/"},{"title":"vf_qrestore","text":"本文档记录qiyi-filter的生成和使用方法 文件说明 涉及到四个文件vf_qrestore.c qrestore.h qrestore.cpp vf_qrestore 提供的是qiyi-ffmpeg数据到libtorch数据转换和接口调用 qrestore 实现了质量恢复方法，提供c wrapper调用 c++接口函数和libtorch库文件 集成步骤集成步骤主要分四部： 所有文件放到libavfilter目录下。 在libavfilter/allfilters.c文件中新增 REGISTER_FILTER(QRESTORE, qrestore, vf); 修改libavfilter/Makefile文件，将需要编译的c文件引用进来OBJS-$(CONFIG_QRESTORE_FILTER) += vf_qrestore.o 修改libavfilter/Makefile文件，将需要编译的cpp和h文件引用进来，在 HEADERS处添加 qrestore.h，在OBJS处添加qrestore.h 配置config-qiyi-simple,链接libtorch库，这里给出config-qiyi-simple配置： ./configure --enable-yasm --enable-static --enable-nonfree --enable-gpl --disable-filter=intertrustwm --disable-filter=iqiyiwm --disable-filter=css --disable-optimizations --extra-cflags=\"-I/data/source/wrappertest/src -I/data/source/Qrestore/src -I/data/source/pytorch/torch/lib/tmp_install/include\" --extra-cxxflags=\"-std=c++11\" --extra-ldflags=\"-L/data/source/pytorch/torch/lib/tmp_install/lib -L/usr/local/cuda/lib64 -L/usr/local/lib -L/data/source/wrappertest/src -L/data/source/Qrestore/src/build\" --extra-libs=\"-lCppAddWrapper -lCppAdd -ltorch -lcuda -lnvrtc -lnvToolsExt -lcudart_static -lpthread -ldl -lrt -lcaffe2 -lcaffe2_gpu -lc10 -lc10_cuda -lcufft -lcurand -lcudnn -lculibos -lcublas -lcublas_device -lstdc++\" --prefix=/usr/local/ffmpeg_new_master 使用filter使用./ffmpeg -i input -vf qrestore output 函数调用: #include \"qrestore.h\": void *qRestoreObj = getQRestoreObj(); // get class QRestore object: getQFixedFrame(...); // fix frame: rgb24_to_yuv420(...); // result rgb convert to yuv@param: qRestoreObjvoid getQFixedFrame(void *qRestoreObj, uint8_t *src, uint8_t *dst, int width, int height, char *modelPath)","link":"/2018/12/25/vf-qrestore/"},{"title":"vim-using-skill","text":"命令 Home键或数字0快速定位到行首，End键定位到行末 $键前加数字表示移动的行数，1$表示当前行的行尾，2$表示当前行的下一行的行尾 gg跳转到第一行，Shift+g, G跳转到最后一行 Ctrl + s 锁定当前终端， Ctrl + q 解锁","link":"/2018/12/19/vim-using-skill/"},{"title":"图像视频质量","text":"探究图像和视频质量问题","link":"/2018/09/20/image-video-quality/"},{"title":"HDR-Project","text":"记录HDR开发过程中的一些细节 FLAGS2018-12-28 11:15:43, [data_augmentation_size] : 82018-12-28 11:15:43, [data_compute_dtype] : &lt;class 'numpy.float32'&gt;2018-12-28 11:15:43, [data_csr_buffer_size] : 15002018-12-28 11:15:43, [data_image_channel] : 32018-12-28 11:15:43, [data_image_size] : 5122018-12-28 11:15:43, [data_input_dtype] : &lt;class 'numpy.uint8'&gt;2018-12-28 11:15:43, [data_input_ext] : .tif2018-12-28 11:15:43, [data_label_dtype] : &lt;class 'numpy.uint8'&gt;2018-12-28 11:15:43, [data_test_image_count] : 4982018-12-28 11:15:43, [data_train_batch_count] : 60002018-12-28 11:15:43, [data_train_batch_size] : 32018-12-28 11:15:43, [data_train_image_count_input] : 22502018-12-28 11:15:43, [data_train_image_count_label] : 6272018-12-28 11:15:43, [data_train_sample_count_input] : 180002018-12-28 11:15:43, [data_train_sample_count_label] : 50162018-12-28 11:15:43, [data_use_random_pad] : False2018-12-28 11:15:43, [folder_csrs] : /data/LPGAN/csrs/2018-12-28 11:15:43, [folder_csrs_rgb] : /data/LPGAN/csrs_rgb/2018-12-28 11:15:43, [folder_input] : /data/LPGAN/input/2018-12-28 11:15:43, [folder_label] : /data/LPGAN/label/2018-12-28 11:15:43, [folder_label_HDR] : /data/LPGAN/label_HDR/2018-12-28 11:15:43, [folder_log] : /data/LPGAN-Result/736-DGX-LPGAN/log/2018-12-28 11:15:43, [folder_model] : /data/LPGAN-Result/736-DGX-LPGAN/model/2018-12-28 11:15:43, [folder_test_csrs] : /data/LPGAN/csrs/2018-12-28 11:15:43, [folder_test_img] : /data/LPGAN-Result/736-DGX-LPGAN/test_img/2018-12-28 11:15:43, [folder_test_netG_loss] : /data/LPGAN-Result/736-DGX-LPGAN/test_netG_loss/2018-12-28 11:15:43, [folder_test_netG_psnr1] : /data/LPGAN-Result/736-DGX-LPGAN/test_netG_psnr1/2018-12-28 11:15:43, [folder_test_netG_psnr2] : /data/LPGAN-Result/736-DGX-LPGAN/test_netG_psnr2/2018-12-28 11:15:43, [folder_train_ind_input] : /data/LPGAN-Result/736-DGX-LPGAN/train_ind_input/2018-12-28 11:15:43, [folder_train_ind_label] : /data/LPGAN-Result/736-DGX-LPGAN/train_ind_label/2018-12-28 11:15:43, [folder_train_netG_loss] : /data/LPGAN-Result/736-DGX-LPGAN/train_netG_loss/2018-12-28 11:15:43, [folder_weight] : /data/LPGAN-Result/736-DGX-LPGAN/weight/2018-12-28 11:15:43, [format_log_step] : %.3f2018-12-28 11:15:43, [format_log_value] : &#123;:6.4f&#125;2018-12-28 11:15:43, [load_model_need] : False2018-12-28 11:15:43, [load_model_path] : /data/LPGAN-Result/000-DGX-LPGAN/model/0.000.ckpt2018-12-28 11:15:43, [load_path] : /data/LPGAN-Result/000-DGX-LPGAN/2018-12-28 11:15:43, [load_previous_epoch] : 02018-12-28 11:15:43, [load_previous_exp] : 02018-12-28 11:15:43, [load_train_indices_input_path] : /data/LPGAN-Result/000-DGX-LPGAN/train_ind_input/0.000.txt2018-12-28 11:15:43, [load_train_indices_label_path] : /data/LPGAN-Result/000-DGX-LPGAN/train_ind_label/0.000.txt2018-12-28 11:15:43, [load_train_loss_path] : /data/LPGAN-Result/000-DGX-LPGAN/train_netG_loss/0.000.txt2018-12-28 11:15:43, [loss_constant_term] : l22018-12-28 11:15:43, [loss_constant_term_use_local_weight] : False2018-12-28 11:15:43, [loss_constant_term_weight] : 10000.02018-12-28 11:15:43, [loss_data_term_use_local_weight] : False2018-12-28 11:15:43, [loss_heavy] : True2018-12-28 11:15:43, [loss_photorealism_is_our] : True2018-12-28 11:15:43, [loss_pr] : False2018-12-28 11:15:43, [loss_source_data_term] : l22018-12-28 11:15:43, [loss_source_data_term_weight] : 1000.02018-12-28 11:15:43, [loss_wgan_gp_bound] : 0.052018-12-28 11:15:43, [loss_wgan_gp_mv_decay] : 0.992018-12-28 11:15:43, [loss_wgan_gp_times] : 12018-12-28 11:15:43, [loss_wgan_gp_use_all] : False2018-12-28 11:15:43, [loss_wgan_lambda] : 102018-12-28 11:15:43, [loss_wgan_lambda_grow] : 2.02018-12-28 11:15:43, [loss_wgan_lambda_ignore] : 12018-12-28 11:15:43, [loss_wgan_use_g_to_one] : False2018-12-28 11:15:43, [method] : WGAN-v24-cycleganD22018-12-28 11:15:43, [mode_use_debug] : False2018-12-28 11:15:43, [netD_base_learning_decay] : 752018-12-28 11:15:43, [netD_base_learning_decay_epoch] : 752018-12-28 11:15:43, [netD_base_learning_rate] : 1e-052018-12-28 11:15:43, [netD_buffer_times] : 502018-12-28 11:15:43, [netD_init_method] : var_scale2018-12-28 11:15:43, [netD_init_times] : 02018-12-28 11:15:43, [netD_init_weight] : 0.0012018-12-28 11:15:43, [netD_mat] : /data/LPGAN-Result/736-DGX-LPGAN/736-netD.mat2018-12-28 11:15:43, [netD_regularization_weight] : 02018-12-28 11:15:43, [netD_times] : 502018-12-28 11:15:43, [netD_times_grow] : 12018-12-28 11:15:43, [netG_base_learning_decay] : 752018-12-28 11:15:43, [netG_base_learning_decay_epoch] : 752018-12-28 11:15:43, [netG_base_learning_rate] : 1e-052018-12-28 11:15:43, [netG_init_method] : var_scale2018-12-28 11:15:43, [netG_init_weight] : 0.0012018-12-28 11:15:43, [netG_mat] : /data/LPGAN-Result/736-DGX-LPGAN/736-netG.mat2018-12-28 11:15:43, [netG_regularization_weight] : 02018-12-28 11:15:43, [net_gradient_clip_value] : 100000000.02018-12-28 11:15:43, [num_exp] : 7362018-12-28 11:15:43, [num_gpu] : 42018-12-28 11:15:43, [path_char] : /2018-12-28 11:15:43, [path_data] : /data/LPGAN2018-12-28 11:15:43, [path_result] : /data/LPGAN-Result/736-DGX-LPGAN2018-12-28 11:15:43, [path_result_root] : /data/LPGAN-Result/%03d-DGX-LPGAN2018-12-28 11:15:43, [process_epoch] : 02018-12-28 11:15:43, [process_load_test_batch_capacity] : 322018-12-28 11:15:43, [process_load_train_batch_capacity] : 642018-12-28 11:15:43, [process_max_epoch] : 1502018-12-28 11:15:43, [process_random_seed] : 22018-12-28 11:15:43, [process_run_first_testing_epoch] : True2018-12-28 11:15:43, [process_test_drop_summary_step] : 12018-12-28 11:15:43, [process_test_log_interval_epoch] : 22018-12-28 11:15:43, [process_train_data_loader_count] : 22018-12-28 11:15:43, [process_train_drop_summary_step] : 52018-12-28 11:15:43, [process_train_log_interval_epoch] : 202018-12-28 11:15:43, [process_write_test_img_count] : 4982018-12-28 11:15:43, [sys_is_dgx] : True2018-12-28 11:15:43, [sys_use_all_gpu_memory] : True2018-12-28 11:15:43, [sys_use_unix] : True2018-12-28 11:15:43, [txt_log] : /data/LPGAN-Result/736-DGX-LPGAN/736-log.txt2018-12-28 11:15:43, [txt_test] : /data/LPGAN/test.txt2018-12-28 11:15:43, [txt_train_input] : `/data/LPGAN/train_input.txt`2018-12-28 11:15:43, [txt_train_label] : /data/LPGAN/train_label.txt ARCHITECTURE2018-12-28 11:10:35, [netG] architecture_log :2018-12-28 11:10:50, ========== net_name = netG_1 ==========2018-12-28 11:10:54, [ input][ 0] : ( 3, 512, 512, 3)2018-12-28 11:10:58, [ conv][ 1] : ( 3, 512, 512, 16)2018-12-28 11:10:59, [ selu][ 2] : ( 3, 512, 512, 16)2018-12-28 11:11:00, [ bn][ 3] : ( 3, 512, 512, 16)2018-12-28 11:11:01, [ conv][ 4] : ( 3, 256, 256, 32)2018-12-28 11:11:01, [ selu][ 5] : ( 3, 256, 256, 32)2018-12-28 11:11:02, [ bn][ 6] : ( 3, 256, 256, 32)2018-12-28 11:11:02, [ conv][ 7] : ( 3, 128, 128, 64)2018-12-28 11:11:04, [ selu][ 8] : ( 3, 128, 128, 64)2018-12-28 11:11:05, [ bn][ 9] : ( 3, 128, 128, 64)2018-12-28 11:11:05, [ conv][ 10] : ( 3, 64, 64, 128)2018-12-28 11:11:06, [ selu][ 11] : ( 3, 64, 64, 128)2018-12-28 11:11:06, [ bn][ 12] : ( 3, 64, 64, 128)2018-12-28 11:11:07, [ conv][ 13] : ( 3, 32, 32, 128)2018-12-28 11:11:07, [ selu][ 14] : ( 3, 32, 32, 128)2018-12-28 11:11:09, [ bn][ 15] : ( 3, 32, 32, 128)2018-12-28 11:11:17, ========== net_name = netG_2 ==========2018-12-28 11:11:18, [ input][ 15] : ( 3, 32, 32, 128)2018-12-28 11:11:18, [ conv][ 16] : ( 3, 16, 16, 128)2018-12-28 11:11:19, [ selu][ 17] : ( 3, 16, 16, 128)2018-12-28 11:11:20, [ bn][ 18] : ( 3, 16, 16, 128)2018-12-28 11:11:20, [ conv][ 19] : ( 3, 8, 8, 128)2018-12-28 11:11:21, [ selu][ 20] : ( 3, 8, 8, 128)2018-12-28 11:11:22, [ bn][ 21] : ( 3, 8, 8, 128)2018-12-28 11:11:22, [ conv][ 22] : ( 3, 1, 1, 128)2018-12-28 11:11:23, [ selu][ 23] : ( 3, 1, 1, 128)2018-12-28 11:11:23, [ conv][ 24] : ( 3, 1, 1, 128)2018-12-28 11:11:24, ========== net_name = netG_3 ==========2018-12-28 11:11:25, [ input][ 15] : ( 3, 32, 32, 128)2018-12-28 11:11:25, [ conv][ 25] : ( 3, 32, 32, 128)2018-12-28 11:11:26, [ g_concat][ 26] : ( 3, 32, 32, 256), use index [ 24] : ( 3, 1, 1, 128)2018-12-28 11:12:12, [ conv][ 27] : ( 3, 32, 32, 128)2018-12-28 11:12:13, [ selu][ 28] : ( 3, 32, 32, 128)2018-12-28 11:12:15, [ bn][ 29] : ( 3, 32, 32, 128)2018-12-28 11:12:16, [ conv][ 30] : ( 3, 32, 32, 128)2018-12-28 11:12:18, [ resize][ 31] : ( 3, 64, 64, 128)2018-12-28 11:12:18, [ concat][ 32] : ( 3, 64, 64, 256), use index [ 10] : ( 3, 64, 64, 128)2018-12-28 11:12:19, [ selu][ 33] : ( 3, 64, 64, 256)2018-12-28 11:12:19, [ bn][ 34] : ( 3, 64, 64, 256)2018-12-28 11:12:20, [ conv][ 35] : ( 3, 64, 64, 128)2018-12-28 11:12:21, [ resize][ 36] : ( 3, 128, 128, 128)2018-12-28 11:12:21, [ concat][ 37] : ( 3, 128, 128, 192), use index [ 7] : ( 3, 128, 128, 64)2018-12-28 11:12:22, [ selu][ 38] : ( 3, 128, 128, 192)2018-12-28 11:12:23, [ bn][ 39] : ( 3, 128, 128, 192)2018-12-28 11:12:24, [ conv][ 40] : ( 3, 128, 128, 64)2018-12-28 11:12:24, [ resize][ 41] : ( 3, 256, 256, 64)2018-12-28 11:12:25, [ concat][ 42] : ( 3, 256, 256, 96), use index [ 4] : ( 3, 256, 256, 32)2018-12-28 11:12:26, [ selu][ 43] : ( 3, 256, 256, 96)2018-12-28 11:12:42, [ bn][ 44] : ( 3, 256, 256, 96)2018-12-28 11:12:43, [ conv][ 45] : ( 3, 256, 256, 32)2018-12-28 11:12:44, [ resize][ 46] : ( 3, 512, 512, 32)2018-12-28 11:12:44, [ concat][ 47] : ( 3, 512, 512, 48), use index [ 1] : ( 3, 512, 512, 16)2018-12-28 11:12:45, [ selu][ 48] : ( 3, 512, 512, 48)2018-12-28 11:12:46, [ bn][ 49] : ( 3, 512, 512, 48)2018-12-28 11:12:47, [ conv][ 50] : ( 3, 512, 512, 16)2018-12-28 11:12:47, [ selu][ 51] : ( 3, 512, 512, 16)2018-12-28 11:12:49, [ bn][ 52] : ( 3, 512, 512, 16)2018-12-28 11:12:50, [ conv][ 53] : ( 3, 512, 512, 3)2018-12-28 11:12:50, [ res][ 54] : ( 3, 512, 512, 3), use index [ 0] : ( 3, 512, 512, 3)2018-12-28 11:12:51, ========== net_name = netG_1 ==========2018-12-28 11:12:51, [ input][ 0] : ( 3, 512, 512, 3)2018-12-28 11:12:51, [ conv][ 1] : ( 3, 512, 512, 16)2018-12-28 11:12:52, [ selu][ 2] : ( 3, 512, 512, 16)2018-12-28 11:12:52, [ bn][ 3] : ( 3, 512, 512, 16)2018-12-28 11:12:52, [ conv][ 4] : ( 3, 256, 256, 32)2018-12-28 11:12:53, [ selu][ 5] : ( 3, 256, 256, 32)2018-12-28 11:12:53, [ bn][ 6] : ( 3, 256, 256, 32)2018-12-28 11:12:53, [ conv][ 7] : ( 3, 128, 128, 64)2018-12-28 11:12:54, [ selu][ 8] : ( 3, 128, 128, 64)2018-12-28 11:12:54, [ bn][ 9] : ( 3, 128, 128, 64)2018-12-28 11:12:54, [ conv][ 10] : ( 3, 64, 64, 128)2018-12-28 11:12:55, [ selu][ 11] : ( 3, 64, 64, 128)2018-12-28 11:12:55, [ bn][ 12] : ( 3, 64, 64, 128)2018-12-28 11:12:56, [ conv][ 13] : ( 3, 32, 32, 128)2018-12-28 11:12:56, [ selu][ 14] : ( 3, 32, 32, 128)2018-12-28 11:13:17, [ bn][ 15] : ( 3, 32, 32, 128)2018-12-28 11:13:17, ========== net_name = netG_2 ==========2018-12-28 11:13:18, [ input][ 15] : ( 3, 32, 32, 128)2018-12-28 11:13:18, [ conv][ 16] : ( 3, 16, 16, 128)2018-12-28 11:13:19, [ selu][ 17] : ( 3, 16, 16, 128)2018-12-28 11:13:19, [ bn][ 18] : ( 3, 16, 16, 128)2018-12-28 11:13:19, [ conv][ 19] : ( 3, 8, 8, 128)2018-12-28 11:13:20, [ selu][ 20] : ( 3, 8, 8, 128)2018-12-28 11:13:20, [ bn][ 21] : ( 3, 8, 8, 128)2018-12-28 11:13:23, [ conv][ 22] : ( 3, 1, 1, 128)2018-12-28 11:13:23, [ selu][ 23] : ( 3, 1, 1, 128)2018-12-28 11:13:23, [ conv][ 24] : ( 3, 1, 1, 128)2018-12-28 11:13:24, ========== net_name = netG_3 ==========2018-12-28 11:13:24, [ input][ 15] : ( 3, 32, 32, 128)2018-12-28 11:13:24, [ conv][ 25] : ( 3, 32, 32, 128)2018-12-28 11:13:25, [ g_concat][ 26] : ( 3, 32, 32, 256), use index [ 24] : ( 3, 1, 1, 128)2018-12-28 11:13:25, [ conv][ 27] : ( 3, 32, 32, 128)2018-12-28 11:13:26, [ selu][ 28] : ( 3, 32, 32, 128)2018-12-28 11:13:26, [ bn][ 29] : ( 3, 32, 32, 128)2018-12-28 11:13:26, [ conv][ 30] : ( 3, 32, 32, 128)2018-12-28 11:13:27, [ resize][ 31] : ( 3, 64, 64, 128)2018-12-28 11:13:27, [ concat][ 32] : ( 3, 64, 64, 256), use index [ 10] : ( 3, 64, 64, 128)2018-12-28 11:13:27, [ selu][ 33] : ( 3, 64, 64, 256)2018-12-28 11:13:28, [ bn][ 34] : ( 3, 64, 64, 256)2018-12-28 11:13:28, [ conv][ 35] : ( 3, 64, 64, 128)2018-12-28 11:13:28, [ resize][ 36] : ( 3, 128, 128, 128)2018-12-28 11:13:29, [ concat][ 37] : ( 3, 128, 128, 192), use index [ 7] : ( 3, 128, 128, 64)2018-12-28 11:13:29, [ selu][ 38] : ( 3, 128, 128, 192)2018-12-28 11:13:29, [ bn][ 39] : ( 3, 128, 128, 192)2018-12-28 11:13:30, [ conv][ 40] : ( 3, 128, 128, 64)2018-12-28 11:13:30, [ resize][ 41] : ( 3, 256, 256, 64)2018-12-28 11:13:31, [ concat][ 42] : ( 3, 256, 256, 96), use index [ 4] : ( 3, 256, 256, 32)2018-12-28 11:13:31, [ selu][ 43] : ( 3, 256, 256, 96)2018-12-28 11:13:31, [ bn][ 44] : ( 3, 256, 256, 96)2018-12-28 11:13:32, [ conv][ 45] : ( 3, 256, 256, 32)2018-12-28 11:13:32, [ resize][ 46] : ( 3, 512, 512, 32)2018-12-28 11:13:32, [ concat][ 47] : ( 3, 512, 512, 48), use index [ 1] : ( 3, 512, 512, 16)2018-12-28 11:13:33, [ selu][ 48] : ( 3, 512, 512, 48)2018-12-28 11:13:33, [ bn][ 49] : ( 3, 512, 512, 48)2018-12-28 11:13:34, [ conv][ 50] : ( 3, 512, 512, 16)2018-12-28 11:13:34, [ selu][ 51] : ( 3, 512, 512, 16)2018-12-28 11:13:34, [ bn][ 52] : ( 3, 512, 512, 16)2018-12-28 11:13:35, [ conv][ 53] : ( 3, 512, 512, 3)2018-12-28 11:13:35, [ res][ 54] : ( 3, 512, 512, 3), use index [ 0] : ( 3, 512, 512, 3)2018-12-28 11:13:36, [netD] architecture_log :2018-12-28 11:13:36, ========== net_name = netD_1 ==========2018-12-28 11:13:36, [ input][ 0] : ( 3, 512, 512, 3)2018-12-28 11:13:36, [ conv][ 1] : ( 3, 512, 512, 16)2018-12-28 11:13:38, [ lrelu][ 2] : ( 3, 512, 512, 16)2018-12-28 11:13:39, [ in][ 3] : ( 3, 512, 512, 16)2018-12-28 11:13:39, [ conv][ 4] : ( 3, 256, 256, 32)2018-12-28 11:13:39, [ lrelu][ 5] : ( 3, 256, 256, 32)2018-12-28 11:13:40, [ in][ 6] : ( 3, 256, 256, 32)2018-12-28 11:13:40, [ conv][ 7] : ( 3, 128, 128, 64)2018-12-28 11:13:41, [ lrelu][ 8] : ( 3, 128, 128, 64)2018-12-28 11:14:02, [ in][ 9] : ( 3, 128, 128, 64)2018-12-28 11:14:02, [ conv][ 10] : ( 3, 64, 64, 128)2018-12-28 11:14:02, [ lrelu][ 11] : ( 3, 64, 64, 128)2018-12-28 11:14:03, [ in][ 12] : ( 3, 64, 64, 128)2018-12-28 11:14:03, [ conv][ 13] : ( 3, 32, 32, 128)2018-12-28 11:14:03, [ lrelu][ 14] : ( 3, 32, 32, 128)2018-12-28 11:14:04, [ in][ 15] : ( 3, 32, 32, 128)2018-12-28 11:14:05, [ conv][ 16] : ( 3, 16, 16, 128)2018-12-28 11:14:05, [ lrelu][ 17] : ( 3, 16, 16, 128)2018-12-28 11:14:05, [ in][ 18] : ( 3, 16, 16, 128)2018-12-28 11:14:06, [ conv][ 19] : ( 3, 1, 1, 1)2018-12-28 11:14:06, [ reduce_mean][ 20] : ( 3)2018-12-28 11:14:06, ========== net_name = netD_1 ==========2018-12-28 11:14:07, [ input][ 0] : ( 3, 512, 512, 3)2018-12-28 11:14:07, [ conv][ 1] : ( 3, 512, 512, 16)2018-12-28 11:14:07, [ lrelu][ 2] : ( 3, 512, 512, 16)2018-12-28 11:14:08, [ in][ 3] : ( 3, 512, 512, 16)2018-12-28 11:14:08, [ conv][ 4] : ( 3, 256, 256, 32)2018-12-28 11:14:09, [ lrelu][ 5] : ( 3, 256, 256, 32)2018-12-28 11:14:09, [ in][ 6] : ( 3, 256, 256, 32)2018-12-28 11:14:09, [ conv][ 7] : ( 3, 128, 128, 64)2018-12-28 11:14:10, [ lrelu][ 8] : ( 3, 128, 128, 64)2018-12-28 11:14:10, [ in][ 9] : ( 3, 128, 128, 64)2018-12-28 11:14:10, [ conv][ 10] : ( 3, 64, 64, 128)2018-12-28 11:14:11, [ lrelu][ 11] : ( 3, 64, 64, 128)2018-12-28 11:14:11, [ in][ 12] : ( 3, 64, 64, 128)2018-12-28 11:14:11, [ conv][ 13] : ( 3, 32, 32, 128)2018-12-28 11:14:11, [ lrelu][ 14] : ( 3, 32, 32, 128)2018-12-28 11:14:12, [ in][ 15] : ( 3, 32, 32, 128)2018-12-28 11:14:12, [ conv][ 16] : ( 3, 16, 16, 128)2018-12-28 11:14:12, [ lrelu][ 17] : ( 3, 16, 16, 128)2018-12-28 11:14:12, [ in][ 18] : ( 3, 16, 16, 128)2018-12-28 11:14:13, [ conv][ 19] : ( 3, 1, 1, 1)2018-12-28 11:14:13, [ reduce_mean][ 20] : ( 3)","link":"/2018/12/28/HDR-Project/"},{"title":"Deep Generative Adversarial Compression Artifact Removal","text":"论文分析，文章2017年发表在ICCV上，使用GAN做压缩失真消除 这篇文章是2017年ICCV的一篇文章， 主要是用GAN做压缩失真的消除，关于图像和视频压缩失真，前面的文章已经讨论过这个问题，感兴趣的可以查看这篇博客。 整体思路研究深度网络主要关注一下几点： 网络架构：本文使用GAN，一个生成网络和一个判别网络，生成网络使用的一个9层的餐差结构 本文使用GAN，一个生成网络和一个判别网络 网络结构下图是整个网络结构的架构图 损失函数训练结果","link":"/2018/09/20/iccv-2017-gan-ar/"},{"title":"Hexo搭建个人Blog记录","text":"记录了整个站点搭建的过程","link":"/2018/09/20/hexo-next-blog/"}],"tags":[{"name":"lifestyle","slug":"lifestyle","link":"/tags/lifestyle/"},{"name":"guiyang","slug":"guiyang","link":"/tags/guiyang/"},{"name":"AR","slug":"AR","link":"/tags/AR/"},{"name":"architecture","slug":"architecture","link":"/tags/architecture/"},{"name":"topic","slug":"topic","link":"/tags/topic/"},{"name":"report","slug":"report","link":"/tags/report/"},{"name":"i3","slug":"i3","link":"/tags/i3/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"technique","slug":"technique","link":"/tags/technique/"},{"name":"gflags","slug":"gflags","link":"/tags/gflags/"},{"name":"libtorch","slug":"libtorch","link":"/tags/libtorch/"},{"name":"install","slug":"install","link":"/tags/install/"},{"name":"bug","slug":"bug","link":"/tags/bug/"},{"name":"paper","slug":"paper","link":"/tags/paper/"},{"name":"DL","slug":"DL","link":"/tags/DL/"},{"name":"ICCV","slug":"ICCV","link":"/tags/ICCV/"},{"name":"conda","slug":"conda","link":"/tags/conda/"},{"name":"command","slug":"command","link":"/tags/command/"},{"name":"mount","slug":"mount","link":"/tags/mount/"},{"name":"index","slug":"index","link":"/tags/index/"},{"name":"cute","slug":"cute","link":"/tags/cute/"},{"name":"hansome","slug":"hansome","link":"/tags/hansome/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"api","slug":"api","link":"/tags/api/"},{"name":"tmux","slug":"tmux","link":"/tags/tmux/"},{"name":"project","slug":"project","link":"/tags/project/"},{"name":"qrestore","slug":"qrestore","link":"/tags/qrestore/"},{"name":"vim","slug":"vim","link":"/tags/vim/"},{"name":"IQ","slug":"IQ","link":"/tags/IQ/"},{"name":"VQ","slug":"VQ","link":"/tags/VQ/"},{"name":"hdr10","slug":"hdr10","link":"/tags/hdr10/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"}],"categories":[{"name":"lifestyle","slug":"lifestyle","link":"/categories/lifestyle/"},{"name":"topic","slug":"topic","link":"/categories/topic/"},{"name":"architecture","slug":"architecture","link":"/categories/architecture/"},{"name":"report","slug":"report","link":"/categories/report/"},{"name":"guiyang","slug":"lifestyle/guiyang","link":"/categories/lifestyle/guiyang/"},{"name":"i3","slug":"i3","link":"/categories/i3/"},{"name":"gflags","slug":"gflags","link":"/categories/gflags/"},{"name":"project","slug":"topic/project","link":"/categories/topic/project/"},{"name":"paper","slug":"paper","link":"/categories/paper/"},{"name":"conda","slug":"conda","link":"/categories/conda/"},{"name":"topic","slug":"architecture/topic","link":"/categories/architecture/topic/"},{"name":"libtorch","slug":"libtorch","link":"/categories/libtorch/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"人物","slug":"人物","link":"/categories/人物/"},{"name":"pytorch","slug":"pytorch","link":"/categories/pytorch/"},{"name":"linux","slug":"i3/linux","link":"/categories/i3/linux/"},{"name":"tmux","slug":"tmux","link":"/categories/tmux/"},{"name":"libtorch","slug":"gflags/libtorch","link":"/categories/gflags/libtorch/"},{"name":"AR","slug":"topic/project/AR","link":"/categories/topic/project/AR/"},{"name":"DL","slug":"paper/DL","link":"/categories/paper/DL/"},{"name":"technique","slug":"conda/technique","link":"/categories/conda/technique/"},{"name":"bug","slug":"libtorch/bug","link":"/categories/libtorch/bug/"},{"name":"command","slug":"linux/command","link":"/categories/linux/command/"},{"name":"mount","slug":"linux/mount","link":"/categories/linux/mount/"},{"name":"install","slug":"linux/install","link":"/categories/linux/install/"},{"name":"api","slug":"pytorch/api","link":"/categories/pytorch/api/"},{"name":"bug","slug":"pytorch/bug","link":"/categories/pytorch/bug/"},{"name":"technique","slug":"i3/linux/technique","link":"/categories/i3/linux/technique/"},{"name":"technique","slug":"tmux/technique","link":"/categories/tmux/technique/"},{"name":"install","slug":"gflags/libtorch/install","link":"/categories/gflags/libtorch/install/"},{"name":"AR","slug":"paper/DL/AR","link":"/categories/paper/DL/AR/"},{"name":"index","slug":"linux/install/index","link":"/categories/linux/install/index/"},{"name":"bug","slug":"gflags/libtorch/install/bug","link":"/categories/gflags/libtorch/install/bug/"},{"name":"ICCV","slug":"paper/DL/AR/ICCV","link":"/categories/paper/DL/AR/ICCV/"},{"name":"bug","slug":"linux/install/bug","link":"/categories/linux/install/bug/"},{"name":"project","slug":"project","link":"/categories/project/"},{"name":"vim","slug":"vim","link":"/categories/vim/"},{"name":"IQ","slug":"topic/IQ","link":"/categories/topic/IQ/"},{"name":"index","slug":"linux/install/bug/index","link":"/categories/linux/install/bug/index/"},{"name":"qrestore","slug":"project/qrestore","link":"/categories/project/qrestore/"},{"name":"technique","slug":"vim/technique","link":"/categories/vim/technique/"},{"name":"VQ","slug":"topic/IQ/VQ","link":"/categories/topic/IQ/VQ/"},{"name":"hdr10","slug":"project/hdr10","link":"/categories/project/hdr10/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"}]}